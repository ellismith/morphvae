{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "from utils.vmf_batch import vMF\n",
    "from models import PoolingClassifier\n",
    "from utils.rw_utils import load_neurons\n",
    "from utils.cluster_utils import _convert_cluster_results_dict_into_array, get_clustered_rws_agglom, tree_from_clustered_result\n",
    "from utils.sampling_utils import _fill_with_infty, decode_z, sample_rws\n",
    "\n",
    "from utils.training_utils import create_model\n",
    "\n",
    "## plotting ###\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in data\n",
    "neurons = load_neurons('./data/toy_data/3_populations/neurons/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = neurons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>radius</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.02</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.79</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n  type     x     y     z  radius  parent\n",
       "0      0     1  0.00  0.00  0.00     1.0      -1\n",
       "1      1     3  0.46 -1.25  0.12     1.0       0\n",
       "2      2     3  0.86  0.27 -0.14     1.0       1\n",
       "3      3     3  1.24  1.86  1.03     1.0       2\n",
       "4      4     3  1.70  0.57  1.92     1.0       3\n",
       "..   ...   ...   ...   ...   ...     ...     ...\n",
       "195  195     3 -5.02  1.22  0.13     1.0     165\n",
       "196  196     3 -4.59 -0.36  1.51     1.0     166\n",
       "197  197     3 -4.82 -0.72 -0.36     1.0     167\n",
       "198  198     3 -4.79 -2.25  2.75     1.0     167\n",
       "199  199     3 -4.80 -2.15  1.88     1.0     167\n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.to_swc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/toy_data/3_populations/walk_representation_8.npy', 'rb') as f:\n",
    "    walk_representation = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/toy_data/3_populations/iterator/val_iterator.pkl', 'rb') as f:\n",
    "    val_iterator = pickle.load(f)\n",
    "with open('./data/toy_data/3_populations/iterator/test_iterator.pkl', 'rb') as f:\n",
    "    test_iterator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "# get data\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "src_data, trg_data, seq_len, indices, labels = list(test_iterator)[0]\n",
    "rw_i = np.round(trg_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 45.709938049316406\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = dict(input_dim =3, embed_dim=32, hidden_dim=32, latent_dim=32, num_layers = 2, kappa=500, dropout=.1)\n",
    "\n",
    "model = create_model(config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/3_populations/emb32_hid32_lat32_dp0.1_k500_max_frac1.0_run1_best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-21908d251481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/3_populations/emb32_hid32_lat32_dp0.1_k500_max_frac1.0_run1_best.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_walks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalk_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/packages/7x/anaconda3/5.3.0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/3_populations/emb32_hid32_lat32_dp0.1_k500_max_frac1.0_run1_best.pt'"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('./models/3_populations/emb32_hid32_lat32_dp0.1_k500_max_frac1.0_run1_best.pt')\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    bs, n_walks, walk_length, input_dim = src_data.shape\n",
    "    src = src_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    # src = [walk length , bs * n_walks, input_dim]\n",
    "    trg = trg_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    seq_len = seq_len.view(-1).to(device)\n",
    "    output = model(src, seq_len, trg, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/3_populations/losses_emb32_hid32_lat32_dp0.1_k500_max_frac1.0_1.npy', 'rb') as f:\n",
    "    l1 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(l1[:,2] - l1[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_0 = _fill_with_infty(rw_i.reshape(-1,walk_length,3).transpose(0,1), seq_len.reshape(-1))\n",
    "rw_i = rw_0.transpose(0,1).reshape(-1,n_walks,walk_length, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_0 = np.where(labels == 0)[0]\n",
    "indices_1 = np.where(labels == 1)[0]\n",
    "indices_2 = np.where(labels == 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "random_indices = np.array([np.random.choice(indices_0, size=2),\n",
    "                                 np.random.choice(indices_1, size=2),\n",
    "                                 np.random.choice(indices_2, size=2)])\n",
    "random_indices = random_indices.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 18.465579986572266\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_no_intersections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ef4341e10e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrw_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrw_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mno_intersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_no_intersections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrw_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# get the encoded random walks. This only works if I have passed the data through already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_walks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_walks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_walks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_no_intersections' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this was obtained with threshold .5 and merging\n",
    "fig, axes = plt.subplots(3,6, sharex=True, sharey=True, figsize=(12,6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = sns.color_palette('pink', n_colors=4)\n",
    "\n",
    "vmf = vMF(LATENT_DIM, kappa=500)\n",
    "np.random.seed(SEED)\n",
    "k = 0\n",
    "for ix in random_indices:                   \n",
    "    rw_rep = rw_i[ix]\n",
    "    no_intersection = get_no_intersections(rw_rep)\n",
    "    # get the encoded random walks. This only works if I have passed the data through already\n",
    "    mus = model.h[ix*n_walks: ix*n_walks+n_walks]\n",
    "    original_seq_len = seq_len[ix*n_walks: ix*n_walks+n_walks].cpu()\n",
    "    decoded_rws = sample_rws(model,vmf, mus, orig_seq_len=original_seq_len, \n",
    "                             n_samples=2, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "    \n",
    "    # cluster the rws\n",
    "    clustered_rws = []\n",
    "    clustered_results = []\n",
    "    for rws in decoded_rws:\n",
    "        clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.5 )\n",
    "        clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "        clustered_results.append(clus_res)\n",
    "    clustered_rws = np.vstack(clustered_rws)\n",
    "    # reduce to trees\n",
    "    new_neurons = []\n",
    "    for clus_res in clustered_results:\n",
    "        N = tree_from_clustered_result(clus_res)\n",
    "        new_neurons.append(N)\n",
    "    \n",
    "    if k == 0 or k ==3:\n",
    "        c= colors[0]\n",
    "    elif k == 6 or k ==9:\n",
    "        c= colors[1]\n",
    "    elif k == 12 or k ==15:\n",
    "        c= colors[2]    \n",
    "    \n",
    "    neurons[indices[ix]].draw_2D(ax=axes[k], dendrite_color=c, projection='xy')\n",
    "\n",
    "    axes[k].axis('off')\n",
    "\n",
    "    for l in range(k+1,k+3):\n",
    "        \n",
    "        sampled_rws = decoded_rws[l-k-1]\n",
    "        axes[l].plot(sampled_rws[:,:,0].T, sampled_rws[:,:,1].T, c='darkgrey')\n",
    "        axes[l].axis('off')\n",
    "        axes[l].set_aspect('equal')\n",
    "        new_neurons[l-k-1].draw_2D(projection='xy', dendrite_color='k', ax=axes[l])\n",
    "    k += 3\n",
    "fig.subplots_adjust(hspace=-.1, wspace=-.1)\n",
    "#plt.savefig('./pics/ICML/v3/Fig5/toy_data_reconstructions.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = load_neurons('./data/M1_exc_data/neurons/', sort=False)\n",
    "\n",
    "colors =['#338b5f', \n",
    "        '#0d5d7f',\n",
    "        '#55b7a6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/M1_exc_data/walks/walk_representation.npy', 'rb') as f:\n",
    "    walk_representation = np.load(f)\n",
    "\n",
    "with open('./data/M1_exc_data/iterator/m_labels/train_iterator.pkl', 'rb') as f:\n",
    "    train_iterator = pickle.load(f)\n",
    "with open('./data/M1_exc_data/iterator/m_labels/val_iterator.pkl', 'rb') as f:\n",
    "    val_iterator = pickle.load(f)\n",
    "with open('./data/M1_exc_data/iterator/m_labels/test_iterator.pkl', 'rb') as f:\n",
    "    test_iterator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "# get data\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "src_data, trg_data, seq_len, indices, labels = list(val_iterator)[0]\n",
    "rw_i = np.round(trg_data, 2)\n",
    "\n",
    "N, n_walks, walk_length, input_dim = src_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = dict(input_dim =3, embed_dim=32, hidden_dim=32, latent_dim=32, num_layers = 2, kappa=500, dropout=.1)\n",
    "\n",
    "model = create_model(config, device)\n",
    "\n",
    "LATENT_DIM = config['latent_dim']\n",
    "\n",
    "# model with the best validation loss \n",
    "state_dict = torch.load('./models/M1_exc/m_label/finetuned_vae_k500_frac1.0_best_run2.pt', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    bs, n_walks, walk_length, input_dim = src_data.shape\n",
    "    src = src_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    # src = [walk length , bs * n_walks, input_dim]\n",
    "    trg = trg_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    seq_len = seq_len.view(-1).to(device)\n",
    "    output = model(src, seq_len, trg, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_0 = _fill_with_infty(rw_i.reshape(-1,walk_length,input_dim).transpose(0,1), seq_len.reshape(-1))\n",
    "rw_i = rw_0.transpose(0,1).reshape(-1,n_walks,walk_length, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_0 = np.where(labels == 0)[0]\n",
    "indices_1 = np.where(labels == 1)[0]\n",
    "indices_2 = np.where(labels == 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample one neuron and check how it looks\n",
    "model.eval()\n",
    "vmf = vMF(LATENT_DIM, kappa=500)\n",
    "ix =8\n",
    "rw_rep = rw_i[ix]\n",
    "walk_length=32\n",
    "\n",
    "# get the encoded random walks. This only works if I have passed the data through already\n",
    "mus = model.h[ix*n_walks: ix*n_walks+n_walks]\n",
    "orig_seq_len = seq_len[ix*n_walks: ix*n_walks+n_walks].cpu()\n",
    "decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=orig_seq_len,\n",
    "                         n_samples=3, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "\n",
    "# cluster the rws\n",
    "clustered_rws = []\n",
    "clustered_results = []\n",
    "stems = len(neurons[ix].edges(1))\n",
    "for rws in decoded_rws:\n",
    "    clus_res, clus_rws = get_clustered_rws_agglom(rws, dist_thresh=.4)\n",
    "#     clus_res = cluster_rws_soma2tip(rws, stems,dist_thresh=1.2)\n",
    "    clus_rws = _convert_cluster_results_dict_into_array(rws.shape, clus_res)\n",
    "    clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "    clustered_results.append(clus_res)\n",
    "clustered_rws = np.vstack(clustered_rws)\n",
    "# reduce to trees\n",
    "new_neurons = []\n",
    "for clus_res in clustered_results:\n",
    "    N = tree_from_clustered_result(clus_res)\n",
    "    new_neurons.append(N)\n",
    "    \n",
    "    \n",
    "fig, axes = plt.subplots(1,4, sharex=True, sharey=True, figsize=(16,4))\n",
    "neurons[indices[ix]].draw_2D(ax=axes[0], dendrite_color='k', projection='xz')\n",
    "axes[0].plot(rw_rep[:,:,0].T, rw_rep[:,:,2].T, c='darkgrey')\n",
    "axes[0].axis('off')\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "for l in range(1,4):    \n",
    "    sampled_rws = decoded_rws[l-1]\n",
    "    axes[l].plot(sampled_rws[:,:,0].T, sampled_rws[:,:,2].T, c='darkgrey')\n",
    "    axes[l].axis('off')\n",
    "    new_neurons[l-1].draw_2D(projection='xz', dendrite_color='k', ax=axes[l])\n",
    "    axes[l].set_aspect('equal')\n",
    "fig.subplots_adjust( wspace=-.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for plotting single examples\n",
    "\n",
    "fig, axes = plt.subplots(1,2, sharex=True, sharey=True, figsize=(4,4))\n",
    "l = 1\n",
    "neurons[indices[ix]].draw_2D(ax=axes[0], dendrite_color=colors[l], projection='xz')\n",
    "axes[0].axis('off')\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "inset_axis = axes[0].inset_axes([.7,.8,.5,.5])\n",
    "neurons[indices[ix]].draw_2D(ax=inset_axis, dendrite_color=colors[l], projection='xy', linewidth=2)\n",
    "inset_axis.axis('off')\n",
    "inset_axis.set_aspect('equal')\n",
    "\n",
    "d_ix = 0\n",
    "sampled_rws = decoded_rws[d_ix]\n",
    "axes[1].plot(sampled_rws[:,:,0].T, sampled_rws[:,:,2].T, c='darkgrey')\n",
    "axes[1].axis('off')\n",
    "new_neurons[d_ix].draw_2D(projection='xz', dendrite_color='k', ax=axes[1],linewidth=2)\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "inset_axis_sample = axes[1].inset_axes([.7,.8,.5,.5])\n",
    "# inset_axis_sample.plot(sampled_rws[:,:,0].T, sampled_rws[:,:,2].T, c='darkgrey')\n",
    "new_neurons[d_ix].draw_2D(ax=inset_axis_sample, dendrite_color='k', projection='xy',linewidth=2)\n",
    "inset_axis_sample.axis('off')\n",
    "inset_axis_sample.set_aspect('equal')\n",
    "\n",
    "fig.subplots_adjust( wspace=-.1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./pics/ICML/camera-ready/Fig6/untufted_example_1.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting 2 examples per class\n",
    "np.random.seed(SEED-10)\n",
    "# np.random.seed(SEED-2)\n",
    "random_indices = np.array([np.random.choice(indices_0, size=2, replace=False),\n",
    "                                 np.random.choice(indices_1, size=2,replace=False),\n",
    "                                 np.random.choice(indices_2, size=2,replace=False)])\n",
    "random_indices = random_indices.flatten()\n",
    "random_indices\n",
    "\n",
    "colors =['#338b5f', \n",
    "        '#0d5d7f',\n",
    "        '#55b7a6']\n",
    "\n",
    "fig, axes = plt.subplots(3,6, sharex=True, sharey=True, figsize=(18,9))\n",
    "axes = axes.flatten()\n",
    "model.eval()\n",
    "vmf = vMF(LATENT_DIM, kappa=500)\n",
    "\n",
    "k = 0\n",
    "for ix in random_indices:                   \n",
    "    rw_rep = rw_i[ix]\n",
    "\n",
    "    # get the encoded random walks. This only works if I have passed the data through already\n",
    "    mus = model.h[ix*n_walks: ix*n_walks+n_walks]\n",
    "    decoded_rws = sample_rws(model, vmf, mus, n_samples=2, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "    \n",
    "    # cluster the rws\n",
    "    clustered_rws = []\n",
    "    clustered_results = []\n",
    "    for rws in decoded_rws:\n",
    "        clus_res, clus_rws = get_clustered_rws_agglom(rws, dist_thresh=.4)\n",
    "        clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "        clustered_results.append(clus_res)\n",
    "    clustered_rws = np.vstack(clustered_rws)\n",
    "    # reduce to trees\n",
    "    new_neurons = []\n",
    "    for clus_res in clustered_results:\n",
    "        N = tree_from_clustered_result(clus_res)\n",
    "        new_neurons.append(N)\n",
    "    \n",
    "    if k == 0 or k ==3:\n",
    "        c= colors[0]\n",
    "    elif k == 6 or k ==9:\n",
    "        c= colors[1]\n",
    "    elif k == 12 or k ==15:\n",
    "        c= colors[2]  \n",
    "    \n",
    "    neurons[indices[ix]].draw_2D(ax=axes[k], dendrite_color=c, projection='xz')\n",
    "    #_ = axes[k].plot(rw_rep[:,:,0].T, rw_rep[:,:,2].T, c='grey', alpha=.1)\n",
    "    axes[k].axis('off')\n",
    "\n",
    "    for l in range(k+1,k+3):\n",
    "        \n",
    "        sampled_rws = decoded_rws[l-k-1]\n",
    "        axes[l].plot(sampled_rws[:,:,0].T, sampled_rws[:,:,2].T, c='darkgrey')\n",
    "        axes[l].axis('off')\n",
    "        axes[l].set_aspect('equal')\n",
    "        new_neurons[l-k-1].draw_2D(projection='xz', dendrite_color='k', ax=axes[l])\n",
    "    k += 3\n",
    "fig.subplots_adjust(hspace=-.1, wspace=-.2)\n",
    "# plt.savefig('./pics/ICML/v4/Fig6/pyr_data_reconstructions.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhibitory neurons - fine tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "colors = ['#fd9e2b', '#e0285d', '#aa369a', '#fda389']\n",
    "\n",
    "part = 'axon'\n",
    "neurons = load_neurons('./data/M1_inh_data/neurons/%s/'%part, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/M1_inh_data/walks/%s/walk_representation_32.npy'%part, 'rb') as f:\n",
    "    walk_representation = np.load(f)\n",
    "\n",
    "with open('./data/M1_inh_data/iterator/%s/train_iterator_32.pkl'%part, 'rb') as f:\n",
    "    train_iterator = pickle.load(f)\n",
    "with open('./data/M1_inh_data/iterator/%s/val_iterator_32.pkl'%part, 'rb') as f:\n",
    "    val_iterator = pickle.load(f)\n",
    "with open('./data/M1_inh_data/iterator/%s/test_iterator_32.pkl'%part, 'rb') as f:\n",
    "    test_iterator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "\n",
    "# get data\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "src_data, trg_data, seq_len, indices, labels = list(val_iterator)[0]\n",
    "rw_i = np.round(trg_data, 2)\n",
    "\n",
    "N, n_walks, walk_length, input_dim = src_data.shape\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = dict(input_dim =3, embed_dim=32, hidden_dim=32, latent_dim=32, num_layers = 2, kappa=500, dropout=.1)\n",
    "\n",
    "model = create_model(config, device)\n",
    "\n",
    "LATENT_DIM = config['latent_dim']\n",
    "\n",
    "# model with the best validation mse loss \n",
    "state_dict = torch.load('./models/M1_inh/finetuned/%s/finetuned_vae_frac0.5_best_run2.pt'%part)\n",
    "model.load_state_dict(state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the data through the model so we can sample new examples in the the latent space\n",
    "with torch.no_grad():\n",
    "    bs, n_walks, walk_length, input_dim = src_data.shape\n",
    "    src = src_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    # src = [walk length , bs * n_walks, input_dim]\n",
    "    trg = trg_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    seq_len = seq_len.view(-1).to(device)\n",
    "    output = model(src, seq_len, trg, 0)\n",
    "    \n",
    "rw_0 = _fill_with_infty(rw_i.reshape(-1,walk_length,input_dim).transpose(0,1), seq_len.reshape(-1))\n",
    "rw_i = rw_0.transpose(0,1).reshape(-1,n_walks,walk_length, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_0 = np.where(labels == 0)[0]\n",
    "indices_1 = np.where(labels == 1)[0]\n",
    "indices_2 = np.where(labels == 2)[0]\n",
    "indices_3 = np.where(labels == 3)[0]\n",
    "\n",
    "np.random.seed(SEED-2)\n",
    "random_indices = np.array([np.random.choice(indices_0, size=2, replace=False),\n",
    "                                 np.random.choice(indices_1, size=2,replace=False),\n",
    "                                 np.random.choice(indices_2, size=2,replace=False), \n",
    "                                np.random.choice(indices_3, size=2,replace=False)])\n",
    "random_indices = random_indices.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(labels == 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     37
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample one neuron and check how it looks\n",
    "model.eval()\n",
    "vmf = vMF(LATENT_DIM, kappa=500)\n",
    "ix = 48\n",
    "rw_rep = rw_i[ix]\n",
    "walk_length=32\n",
    "# get the encoded random walks. This only works if I have passed the data through already\n",
    "mus = model.h[ix*n_walks: ix*n_walks+n_walks]\n",
    "orig_seq_len = seq_len[ix*n_walks: ix*n_walks+n_walks].cpu()\n",
    "decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=orig_seq_len,\n",
    "                         n_samples=3, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "\n",
    "# cluster the rws\n",
    "clustered_rws = []\n",
    "clustered_results = []\n",
    "for rws in decoded_rws:\n",
    "    clus_res, clus_rws = get_clustered_rws_agglom(rws, dist_thresh=.3)\n",
    "    clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "    clustered_results.append(clus_res)\n",
    "clustered_rws = np.vstack(clustered_rws)\n",
    "# reduce to trees\n",
    "new_neurons = []\n",
    "for clus_res in clustered_results:\n",
    "    N = tree_from_clustered_result(clus_res)\n",
    "    new_neurons.append(N)\n",
    "    \n",
    "    \n",
    "fig, axes = plt.subplots(1,4, sharex=True, sharey=True, figsize=(16,4))\n",
    "neurons[indices[ix]].draw_2D(ax=axes[0], dendrite_color='k', projection='xz')\n",
    "axes[0].plot(rw_rep[:,:,0].T, rw_rep[:,:,2].T, c='darkgrey')\n",
    "axes[0].axis('off')\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "for l in range(1,4):    \n",
    "    sampled_rws = decoded_rws[l-1]\n",
    "    axes[l].plot(sampled_rws[:,:,0].T, sampled_rws[:,:,2].T, c='darkgrey')\n",
    "    axes[l].axis('off')\n",
    "    new_neurons[l-1].draw_2D(projection='xz', dendrite_color='k', ax=axes[l])\n",
    "    axes[l].set_aspect('equal')\n",
    "fig.subplots_adjust( wspace=-.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, sharex=True, sharey=True, figsize=(4,4))\n",
    "l = 3\n",
    "neurons[indices[ix]].draw_2D(ax=axes[0], axon_color=colors[l], projection='xz')\n",
    "axes[0].axis('off')\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "inset_axis = axes[0].inset_axes([.9,.7,.5,.5])\n",
    "neurons[indices[ix]].draw_2D(ax=inset_axis, axon_color=colors[l], projection='xy')\n",
    "inset_axis.axis('off')\n",
    "# inset_axis.set_aspect('equal')\n",
    "\n",
    "d_ix = 0\n",
    "sampled_rws = decoded_rws[d_ix]\n",
    "axes[1].plot(sampled_rws[:,:,0].T, sampled_rws[:,:,2].T, c='darkgrey')\n",
    "axes[1].axis('off')\n",
    "new_neurons[d_ix].draw_2D(projection='xz', dendrite_color='k', ax=axes[1])\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "inset_axis_sample = axes[1].inset_axes([.9,.7,.5,.5])\n",
    "# inset_axis_sample.plot(sampled_rws[:,:,0].T, sampled_rws[:,:,2].T, c='darkgrey')\n",
    "new_neurons[d_ix].draw_2D(ax=inset_axis_sample, dendrite_color='k', projection='xy')\n",
    "inset_axis_sample.axis('off')\n",
    "inset_axis_sample.set_aspect('equal')\n",
    "\n",
    "# fig.subplots_adjust( wspace=-.1)\n",
    "plt.savefig('./pics/ICML/camera-ready/Fig6/lamp5_example2.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#fd9e2b', '#e0285d', '#aa369a', '#fda389']\n",
    "fig, axes = plt.subplots(4,6, sharex=True, sharey=True, figsize=(24,9))\n",
    "axes = axes.flatten()\n",
    "model.eval()\n",
    "vmf_500 = vMF(LATENT_DIM, kappa=500)\n",
    "\n",
    "k = 0\n",
    "for ix in random_indices:                   \n",
    "    rw_rep = rw_i[ix]\n",
    "\n",
    "    # get the encoded random walks. This only works if I have passed the data through already\n",
    "    mus = model.h[ix*n_walks: ix*n_walks+n_walks]\n",
    "    decoded_rws = sample_rws(vmf_500, mus, n_samples=2, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "    \n",
    "    # cluster the rws\n",
    "    clustered_rws = []\n",
    "    clustered_results = []\n",
    "    for rws in decoded_rws:\n",
    "        clus_res, clus_rws = get_clustered_rws_agglom(rws, dist_thresh=.25)\n",
    "        clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "        clustered_results.append(clus_res)\n",
    "    clustered_rws = np.vstack(clustered_rws)\n",
    "    # reduce to trees\n",
    "    new_neurons = []\n",
    "    for clus_res in clustered_results:\n",
    "        N = tree_from_clustered_result(clus_res)\n",
    "        new_neurons.append(N)\n",
    "    \n",
    "    if k == 0 or k ==3:\n",
    "        c= colors[0]\n",
    "    elif k == 6 or k ==9:\n",
    "        c= colors[1]\n",
    "    elif k == 12 or k ==15:\n",
    "        c= colors[2]  \n",
    "    \n",
    "    neurons[indices[ix]].draw_2D(ax=axes[k], axon_color=c, projection='xz')\n",
    "    axes[k].axis('off')\n",
    "\n",
    "    for l in range(k+1,k+3):\n",
    "        \n",
    "        sampled_rws = decoded_rws[l-k-1]\n",
    "        axes[l].plot(sampled_rws[:,:,0].T, sampled_rws[:,:,2].T, c='darkgrey')\n",
    "        axes[l].axis('off')\n",
    "        new_neurons[l-k-1].draw_2D(projection='xz', dendrite_color='k', ax=axes[l])\n",
    "    k += 3\n",
    "fig.subplots_adjust(hspace=-.2, wspace=-.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Farrow - fine tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002_00535_4L_C01_01-checkpoint.swc\n",
      "0001_00535_1L_C01_01-checkpoint.swc\n"
     ]
    }
   ],
   "source": [
    "part = 'soma_centered'\n",
    "neurons = np.array(load_neurons('./data/Farrow_data/neurons/%s/'%part, sort=False))\n",
    "\n",
    "# get the neuron files in the right order\n",
    "root, _, files = list(os.walk('./data/Farrow_data/neurons/%s/'%part))[0]\n",
    "files = np.array(files)\n",
    "file_ix = files.argsort()\n",
    "neurons = neurons[file_ix]\n",
    "\n",
    "with open('./data/Farrow_data/walks/%s/walk_representation.npy'%part, 'rb') as f:\n",
    "    walk_representation = np.load(f)\n",
    "\n",
    "with open('./data/Farrow_data/iterator/%s/train_iterator.pkl'%part, 'rb') as f:\n",
    "    train_iterator = pickle.load(f)\n",
    "with open('./data/Farrow_data/iterator/%s/val_iterator.pkl'%part, 'rb') as f:\n",
    "    val_iterator = pickle.load(f)\n",
    "with open('./data/Farrow_data/iterator/%s/test_iterator.pkl'%part, 'rb') as f:\n",
    "    test_iterator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 18.465579986572266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 17\n",
    "\n",
    "# get data\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "src_data, trg_data, seq_len, indices, labels = list(test_iterator)[0]\n",
    "rw_i = np.round(trg_data, 2)\n",
    "\n",
    "N, n_walks, walk_length, input_dim = src_data.shape\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = dict(input_dim =3, embed_dim=16, hidden_dim=16, latent_dim=8, num_layers = 2, kappa=500, dropout=.1)\n",
    "\n",
    "model = create_model(config, device)\n",
    "\n",
    "LATENT_DIM = config['latent_dim']\n",
    "\n",
    "# model with the best validation mse loss \n",
    "state_dict = torch.load('./models/Farrow/finetuned/%s/finetuned_vae_frac1.0_best_run1.pt'%part)\n",
    "model.load_state_dict(state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-100,    0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "          10,   11,   12,   13]),\n",
       " array([ 6, 20,  1,  2,  5,  5, 15,  2,  9,  5,  5,  4,  8, 11,  2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_0 = _fill_with_infty(rw_i.reshape(-1,walk_length,input_dim).transpose(0,1), seq_len.reshape(-1))\n",
    "rw_i = rw_0.transpose(0,1).reshape(-1,n_walks,walk_length, input_dim)\n",
    "\n",
    "indices_0 = np.where(labels == 0)[0]\n",
    "indices_1 = np.where(labels == 4)[0]\n",
    "indices_2 = np.where(labels == 5)[0]\n",
    "indices_3 = np.where(labels == 12)[0]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "random_indices = np.array([np.random.choice(indices_0, size=2, replace=False),\n",
    "                                 np.random.choice(indices_1, size=2,replace=False),\n",
    "                                 np.random.choice(indices_2, size=2,replace=False), \n",
    "                                np.random.choice(indices_3, size=2,replace=False)])\n",
    "random_indices = random_indices.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    bs, n_walks, walk_length, input_dim = src_data.shape\n",
    "    src = src_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    # src = [walk length , bs * n_walks, input_dim]\n",
    "    trg = trg_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    seq_len = seq_len.view(-1).to(device)\n",
    "    output = model(src, seq_len, trg, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c6000357ba7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLATENT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWgAAAIMCAYAAABosUWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3V+I5/ddL/7ny12jEGsLZgTZXU3ArXEpQnRY+6MXJ9KKm1zs3lTJgsc/5HRvTL1o8ZCixBIvxPaiIKzaoKVaMHHthS49K3ugpsiRpuyEauhuWJizijush0zbkJtiY+D1u5hp+XYyu/P57nzHz6ffPB6w8H1/Pq985wnD6+aZD5+p7g4AAAAAAP/1vmfsAAAAAAAAb1UKWgAAAACAkShoAQAAAABGoqAFAAAAABiJghYAAAAAYCQKWgAAAACAkexZ0FbVp6rqlar6ym3uV1X9YVWtV9VLVfXTi48JAAAAALB8hjxB++kkp+5w/5Ekx7f/nUvyx/uPBQAAAACw/PYsaLv7H5J8/Q4jZ5L8RW95Ick7qupHFhUQAAAAAGBZLeIdtEeS3Jw5b2xfAwAAAADgDg4v4Dtql2u962DVuWy9BiH33nvvzzz44IML+PHw3eXFF1/8anevjJ3jW+wlTGsv7SRssZcwLXYSpsdewrTsZyere9cu9TuHqu5P8rnuftcu9z6Z5Avd/ez2+XqSh7v73+/0naurq722tnY3meG7WlW92N2rY+fYjb3krWqqe2kneSuzlzAtdhKmx17CtOxnJxfxioOLSX6ltrw7yWt7lbMAAAAAAAx4xUFVPZvk4ST3VdVGkt9N8r1J0t1/kuRSkkeTrCf5RpJfP6iwAAAAAADLZM+CtrvP7nG/k/zGwhIBAAAAALxFLOIVBwAAAAAA3AUFLQAAAADASBS0AAAAAAAjUdACAAAAAIxEQQsAAAAAMBIFLQAAAADASBS0AAAAAAAjUdACAAAAAIxEQQsAAAAAMBIFLQAAAADASBS0AAAAAAAjUdACAAAAAIxkUEFbVaeq6npVrVfVk7vc/9Gqer6qvlxVL1XVo4uPCgAAAACwXPYsaKvqUJLzSR5JciLJ2ao6sWPsd5Jc6O6HkjyW5I8WHRQAAAAAYNkMeYL2ZJL17r7R3a8neS7JmR0zneQHtz+/PcmtxUUEAAAAAFhOhwfMHElyc+a8keRnd8x8NMn/rqoPJrk3yfsWkg4AAAAAYIkNeYK2drnWO85nk3y6u48meTTJZ6rqTd9dVeeqaq2q1jY3N+dPCyycvYRpsZMwPfYSpsVOwvTYS9ifIQXtRpJjM+ejefMrDB5PciFJuvuLSb4/yX07v6i7n+nu1e5eXVlZubvEwELZS5gWOwnTYy9hWuwkTI+9hP0ZUtBeSXK8qh6oqnuy9UfALu6Y+bck702SqvrJbBW0/pcJAAAAAMAd7FnQdvcbSZ5IcjnJy0kudPfVqnq6qk5vj304yQeq6p+TPJvk17p752sQAAAAAACYMeSPhKW7LyW5tOPaUzOfryV5z2KjAQAAAAAstyGvOAAAAAAA4AAoaAEAAAAARqKgBQAAAAAYiYIWAAAAAGAkCloAAAAAgJEoaAEAAAAARqKgBQAAAAAYiYIWAAAAAGAkCloAAAAAgJEoaAEAAAAARqKgBQAAAAAYiYIWAAAAAGAkCloAAAAAgJEMKmir6lRVXa+q9ap68jYzv1RV16rqalX95WJjAgAAAAAsn8N7DVTVoSTnk/x8ko0kV6rqYndfm5k5nuQjSd7T3a9W1Q8fVGAAAAAAgGUx5Anak0nWu/tGd7+e5LkkZ3bMfCDJ+e5+NUm6+5XFxgQAAAAAWD5DCtojSW7OnDe2r816Z5J3VtU/VtULVXVqty+qqnNVtVZVa5ubm3eXGFgoewnTYidheuwlTIudhOmxl7A/Qwra2uVa7zgfTnI8ycNJzib506p6x5v+o+5nunu1u1dXVlbmzQocAHsJ02InYXrsJUyLnYTpsZewP0MK2o0kx2bOR5Pc2mXmb7v7P7v7X5Jcz1ZhCwAAAADAbQwpaK8kOV5VD1TVPUkeS3Jxx8zfJPm5JKmq+7L1yoMbiwwKAAAAALBs9ixou/uNJE8kuZzk5SQXuvtqVT1dVae3xy4n+VpVXUvyfJLf6u6vHVRoAAAAAIBlcHjIUHdfSnJpx7WnZj53kg9t/wMAAAAAYIAhrzgAAAAAAOAAKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJIMK2qo6VVXXq2q9qp68w9z7q6qranVxEQEAAAAAltOeBW1VHUpyPskjSU4kOVtVJ3aZe1uS30zypUWHBAAAAABYRkOeoD2ZZL27b3T360meS3Jml7nfS/KxJP+xwHwAAAAAAEtrSEF7JMnNmfPG9rVvq6qHkhzr7s/d6Yuq6lxVrVXV2ubm5txhgcWzlzAtdhKmx17CtNhJmB57CfszpKCtXa71t29WfU+STyT58F5f1N3PdPdqd6+urKwMTwkcGHsJ02InYXrsJUyLnYTpsZewP0MK2o0kx2bOR5Pcmjm/Lcm7knyhqv41ybuTXPSHwgAAAAAA7mxIQXslyfGqeqCq7knyWJKL37rZ3a91933dfX9335/khSSnu3vtQBIDAAAAACyJPQva7n4jyRNJLid5OcmF7r5aVU9X1emDDggAAAAAsKwODxnq7ktJLu249tRtZh/efywAAAAAgOU35BUHAAAAAAAcAAUtAAAAAMBIFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwEgUtAAAAAMBIFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwEgUtAAAAAMBIFLQAAAAAACNR0AIAAAAAjGRQQVtVp6rqelWtV9WTu9z/UFVdq6qXqurzVfVji48KAAAAALBc9ixoq+pQkvNJHklyIsnZqjqxY+zLSVa7+6eSfDbJxxYdFAAAAABg2Qx5gvZkkvXuvtHdryd5LsmZ2YHufr67v7F9fCHJ0cXGBAAAAABYPkMK2iNJbs6cN7av3c7jSf5uP6EAAAAAAN4KhhS0tcu13nWw6peTrCb5+G3un6uqtapa29zcHJ4SODD2EqbFTsL02EuYFjsJ02MvYX+GFLQbSY7NnI8mubVzqKrel+S3k5zu7m/u9kXd/Ux3r3b36srKyt3kBRbMXsK02EmYHnsJ02InYXrsJezPkIL2SpLjVfVAVd2T5LEkF2cHquqhJJ/MVjn7yuJjAgAAAAAsnz0L2u5+I8kTSS4neTnJhe6+WlVPV9Xp7bGPJ/mBJH9dVf9UVRdv83UAAAAAAGw7PGSouy8lubTj2lMzn9+34FwAAAAAAEtvyCsOAAAAAAA4AApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJIMK2qo6VVXXq2q9qp7c5f73VdVfbd//UlXdv+igAAAAAADLZs+CtqoOJTmf5JEkJ5KcraoTO8YeT/Jqd/94kk8k+YNFBwUAAAAAWDZDnqA9mWS9u2909+tJnktyZsfMmSR/vv35s0neW1W1uJgAAAAAAMvn8ICZI0luzpw3kvzs7Wa6+42qei3JDyX56uxQVZ1Lcm77+M2q+srdhD5g92VH7gmZaja55vMTYweYZS/3Ra75TTXbZPbSTu7bVLPJNT97OZ+p/i6nmiuZbrap5rKT85vq71Ku+Uw1V2Iv5zXV3+VUcyXTzTbVXHe9k9Xddx6o+sUkv9Dd/2P7/N+TnOzuD87MXN2e2dg+/9/tma/d4XvXunv1boMflKnmSqabTa75TDVXMt1scs1nqrmS6WaTaz5TzZVMN5tc85tqNrnmM9VcyXSzyTWfqeZKpptNrvlMNVcy3WxyzWequZLpZlvGXENecbCR5NjM+WiSW7ebqarDSd6e5Ot3EwgAAAAA4K1iSEF7Jcnxqnqgqu5J8liSiztmLib51e3P70/y973Xo7kAAAAAAG9xe76Ddvudsk8kuZzkUJJPdffVqno6yVp3X0zyZ0k+U1Xr2Xpy9rEBP/uZfeQ+SFPNlUw3m1zzmWquZLrZ5JrPVHMl080m13ymmiuZbja55jfVbHLNZ6q5kulmk2s+U82VTDebXPOZaq5kutnkms9UcyXTzbZ0ufZ8By0AAAAAAAdjyCsOAAAAAAA4AApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGMmeBW1VfaqqXqmqr9zmflXVH1bVelW9VFU/vfiYAAAAAADLZ8gTtJ9OcuoO9x9Jcnz737kkf7z/WAAAAAAAy2/Pgra7/yHJ1+8wcibJX/SWF5K8o6p+ZFEBAQAAAACW1eEFfMeRJDdnzhvb1/5952BVncvWU7a59957f+bBBx9cwI+H7y4vvvjiV7t7Zewc32IvYVp7aSdhi72EabGTMD32EqZlPztZ3b33UNX9ST7X3e/a5d7/SvL73f1/ts+fT/I/u/vFO33n6upqr62t3U1m+K5WVS929+rYOXZjL3mrmupe2kneyuwlTIudhOmxlzAt+9nJIe+g3ctGkmMz56NJbi3gewEAAAAAltoiCtqLSX6ltrw7yWvd/abXGwAAAAAA8J32fAdtVT2b5OEk91XVRpLfTfK9SdLdf5LkUpJHk6wn+UaSXz+osAAAAAAAy2TPgra7z+5xv5P8xsISAQAAAAC8RSziFQcAAAAAANwFBS0AAAAAwEgUtAAAAAAAI1HQAgAAAACMREELAAAAADASBS0AAAAAwEgUtAAAAAAAI1HQAgAAAACMREELAAAAADASBS0AAAAAwEgUtAAAAAAAI1HQAgAAAACMZFBBW1Wnqup6Va1X1ZO73P/Rqnq+qr5cVS9V1aOLjwoAAAAAsFz2LGir6lCS80keSXIiydmqOrFj7HeSXOjuh5I8luSPFh0UAAAAAGDZDHmC9mSS9e6+0d2vJ3kuyZkdM53kB7c/vz3JrcVFBAAAAABYTkMK2iNJbs6cN7avzfpokl+uqo0kl5J8cLcvqqpzVbVWVWubm5t3ERdYNHsJ02InYXrsJUyLnYTpsZewP0MK2trlWu84n03y6e4+muTRJJ+pqjd9d3c/092r3b26srIyf1pg4ewlTIudhOmxlzAtdhKmx17C/gwpaDeSHJs5H82bX2HweJILSdLdX0zy/UnuW0RAAAAAAIBlNaSgvZLkeFU9UFX3ZOuPgF3cMfNvSd6bJFX1k9kqaD3TDgAAAABwB3sWtN39RpInklxO8nKSC919taqerqrT22MfTvKBqvrnJM8m+bXu3vkaBAAAAAAAZhweMtTdl7L1x79mrz018/lakvcsNhoAAAAAwHIb8ooDAAAAAAAOgIIWAAAAAGAkCloAAAAAgJEoaAEAAAAARqKgBQAAAAAYiYIWAAAAAGAkCloAAAAAgJEoaAEAAAAARqKgBQAAAAAYiYIWAAAAAGAkCloAAAAAgJEoaAEAAAAARjKooK2qU1V1varWq+rJ28z8UlVdq6qrVfWXi40JAAAAALB8Du81UFWHkpxP8vNJNpJcqaqL3X1tZuZ4ko8keU93v1pVP3xQgQEAAAAAlsWQJ2hPJlnv7hvd/XqS55Kc2THzgSTnu/vVJOnuVxYbEwAAAABg+QwpaI8kuTlz3ti+NuudSd5ZVf9YVS9U1alFBQQAAAAAWFZDCtra5VrvOB9OcjzJw0nOJvnTqnrHm76o6lxVrVXV2ubm5rxZgQNgL2Fa7CRMj72EabGTMD32EvZnSEG7keTYzPloklu7zPxtd/9nd/9LkuvZKmy/Q3c/092r3b26srJyt5mBBbKXMC12EqbHXsK02EmYHnsJ+zOkoL2S5HhVPVBV9yR5LMnFHTN/k+TnkqSq7svWKw9uLDIoAAAAAMCy2bOg7e43kjyR5HKSl5Nc6O6rVfV0VZ3eHruc5GtVdS3J80l+q7u/dlChAQAAAACWweEhQ919KcmlHdeemvncST60/Q8AAAAAgAGGvOIAAAAAAIADoKAFAAAAABiJghYAAAAAYCQKWgAAAACAkShoAQAAAABGoqAFAAAAABiJghYAAAAAYCQKWgAAAACAkShoAQAAAABGoqAFAAAAABiJghYAAAAAYCQKWgAAAACAkShoAQAAAABGMqigrapTVXW9qtar6sk7zL2/qrqqVhcXEQAAAABgOe1Z0FbVoSTnkzyS5ESSs1V1Ype5tyX5zSRfWnRIAAAAAIBlNOQJ2pNJ1rv7Rne/nuS5JGd2mfu9JB9L8h8LzAcAAAAAsLSGFLRHktycOW9sX/u2qnooybHu/tydvqiqzlXVWlWtbW5uzh0WWDx7CdNiJ2F67CVMi52E6bGXsD9DCtra5Vp/+2bV9yT5RJIP7/VF3f1Md6929+rKysrwlMCBsZcwLXYSpsdewrTYSZgeewn7M6Sg3UhybOZ8NMmtmfPbkrwryReq6l+TvDvJRX8oDAAAAADgzoYUtFeSHK+qB6rqniSPJbn4rZvd/Vp339fd93f3/UleSHK6u9cOJDEAAAAAwJLYs6Dt7jeSPJHkcpKXk1zo7qtV9XRVnT7ogAAAAAAAy+rwkKHuvpTk0o5rT91m9uH9xwIAAAAAWH5DXnEAAAAAAMABUNACAAAAAIxEQQsAAAAAMBIFLQAAAADASBS0AAAAAAAjUdACAAAAAIxEQQsAAAAAMBIFLQAAAADASBS0AAAAAAAjUdACAAAAAIxEQQsAAAAAMBIFLQAAAADASAYVtFV1qqquV9V6VT25y/0PVdW1qnqpqj5fVT+2+KgAAAAAAMtlz4K2qg4lOZ/kkSQnkpytqhM7xr6cZLW7fyrJZ5N8bNFBAQAAAACWzZAnaE8mWe/uG939epLnkpyZHeju57v7G9vHF5IcXWxMAAAAAIDlM6SgPZLk5sx5Y/va7Tye5O92u1FV56pqrarWNjc3h6cEDoy9hGmxkzA99hKmxU7C9NhL2J8hBW3tcq13Haz65SSrST6+2/3ufqa7V7t7dWVlZXhK4MDYS5gWOwnTYy9hWuwkTI+9hP05PGBmI8mxmfPRJLd2DlXV+5L8dpL/1t3fXEw8AAAAAIDlNeQJ2itJjlfVA1V1T5LHklycHaiqh5J8Msnp7n5l8TEBAAAAAJbPngVtd7+R5Ikkl5O8nORCd1+tqqer6vT22MeT/ECSv66qf6qqi7f5OgAAAAAAtg15xUG6+1KSSzuuPTXz+X0LzgUAAAAAsPSGvOIAAAAAAIADoKAFAAAAABiJghYAAAAAYCQKWgAAAACAkShoAQAAAABGoqAFAAAAABiJghYAAAAAYCQKWgAAAACAkShoAQAAAABGoqAFAAAAABiJghYAAAAAYCQKWgAAAACAkQwqaKvqVFVdr6r1qnpyl/vfV1V/tX3/S1V1/6KDAgAAAAAsmz0L2qo6lOR8kkeSnEhytqpO7Bh7PMmr3f3jST6R5A8WHRQAAAAAYNkMeYL2ZJL17r7R3a8neS7JmR0zZ5L8+fbnzyZ5b1XV4mICAAAAACyfIQXtkSQ3Z84b29d2nenuN5K8luSHFhEQAAAAAGBZHR4ws9uTsH0XM6mqc0nObR+/WVVfGfDz/6vdl+SrY4e4jalmk2s+PzF2gFn2cl/kmt9Us01mL+3kvk01m1zzs5fzmervcqq5kulmm2ouOzm/qf4u5ZrPVHMl9nJeU/1dTjVXMt1sU8111ztZ3W/qUb9zoOr/S/LR7v6F7fNHkqS7f39m5vL2zBer6nCS/5dkpe/w5VW11t2rdxv8oEw1VzLdbHLNZ6q5kulmk2s+U82VTDebXPOZaq5kutnkmt9Us8k1n6nmSqabTa75TDVXMt1scs1nqrmS6WaTaz5TzZVMN9sy5hryioMrSY5X1QNVdU+Sx5Jc3DFzMcmvbn9+f5K/v1M5CwAAAADAgFccdPcbVfVEkstJDiX5VHdfraqnk6x198Ukf5bkM1W1nuTr2SpxAQAAAAC4gyHvoE13X0pyace1p2Y+/0eSX5zzZz8z5/x/lanmSqabTa75TDVXMt1scs1nqrmS6WaTaz5TzZVMN5tc85tqNrnmM9VcyXSzyTWfqeZKpptNrvlMNVcy3WxyzWequZLpZlu6XHu+gxYAAAAAgIMx5B20AAAAAAAcAAUtAAAAAMBIFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwEgUtAAAAAMBIFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwEgUtAAAAAMBIFLQAAAAAACPZs6Ctqk9V1StV9ZXb3K+q+sOqWq+ql6rqpxcfEwAAAABg+Qx5gvbTSU7d4f4jSY5v/zuX5I/3HwsAAAAAYPntWdB29z8k+fodRs4k+Yve8kKSd1TVjywqIAAAAADAslrEO2iPJLk5c97YvgYAAAAAwB0cXsB31C7XetfBqnPZeg1C7r333p958MEHF/Dj4bvLiy+++NXuXhk7x7fYS5jWXtpJ2GIvYVrsJEyPvYRp2c9OVveuXep3DlXdn+Rz3f2uXe59MskXuvvZ7fP1JA9397/f6TtXV1d7bW3tbjLDd7WqerG7V8fOsRt7yVvVVPfSTvJWZi9hWuwkTI+9hGnZz04u4hUHF5P8Sm15d5LX9ipnAQAAAAAY8IqDqno2ycNJ7quqjSS/m+R7k6S7/yTJpSSPJllP8o0kv35QYQEAAAAAlsmeBW13n93jfif5jYUlAgAAAAB4i1jEKw4AAAAAALgLCloAAAAAgJEoaAEAAAAARqKgBQAAAAAYiYIWAAAAAGAkCloAAAAAgJEoaAEAAAAARqKgBQAAAAAYiYIWAAAAAGAkCloAAAAAgJEoaAEAAAAARqKgBQAAAAAYiYIWAAAAAGAkgwraqjpVVderar2qntzl/o9W1fNV9eWqeqmqHl18VAAAAACA5bJnQVtVh5KcT/JIkhNJzlbViR1jv5PkQnc/lOSxJH+06KAAAAAAAMtmyBO0J5Osd/eN7n49yXNJzuyY6SQ/uP357UluLS4iAAAAAMByGlLQHklyc+a8sX1t1keT/HJVbSS5lOSDu31RVZ2rqrWqWtvc3LyLuMCi2UuYFjsJ02MvYVrsJEyPvYT9GVLQ1i7Xesf5bJJPd/fRJI8m+UxVvem7u/uZ7l7t7tWVlZX50wILZy9hWuwkTI+9hGmxkzA99hL2Z0hBu5Hk2Mz5aN78CoPHk1xIku7+YpLvT3LfIgICAAAAACyrIQXtlSTHq+qBqronW38E7OKOmX9L8t4kqaqfzFZB65l2AAAAAIA72LOg7e43kjyR5HKSl5Nc6O6rVfV0VZ3eHvtwkg9U1T8neTbJr3X3ztcgAAAAAAAw4/CQoe6+lK0//jV77amZz9eSvGex0QAAAAAAltuQVxwAAAAAAHAAFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwEgUtAAAAAMBIFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwEgUtAAAAAMBIFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwkkEFbVWdqqrrVbVeVU/eZuaXqupaVV2tqr9cbEwAAAAAgOVzeK+BqjqU5HySn0+ykeRKVV3s7mszM8eTfCTJe7r71ar64YMKDAAAAACwLIY8QXsyyXp33+ju15M8l+TMjpkPJDnf3a8mSXe/stiYAAAAAADLZ0hBeyTJzZnzxva1We9M8s6q+seqeqGqTu32RVV1rqrWqmptc3Pz7hIDC2UvYVrsJEyPvYRpsZMwPfYS9mdIQVu7XOsd58NJjid5OMnZJH9aVe9403/U/Ux3r3b36srKyrxZgQNgL2Fa7CRMj72EabGTMD32EvZnSEG7keTYzPloklu7zPxtd/9nd/9LkuvZKmwBAAAAALiNIQXtlSTHq+qBqronyWNJLu6Y+ZskP5ckVXVftl55cGORQQEAAAAAls2eBW13v5HkiSSXk7yc5EJ3X62qp6vq9PbY5SRfq6prSZ5P8lvd/bWDCg0AAAAAsAwODxnq7ktJLu249tTM507yoe1/AAAAAAAMMOQVBwAAAAAAHAAFLQAAAADASBS0AAAAAAAjUdACAAAAAIxEQQsAAAAAMBIFLQAAAADASBS0AAAAAAAjUdACAAAAAIxEQQsAAAAAMBIFLQAAAADASBS0AAAAAAAjUdACAAAAAIxkUEFbVaeq6npVrVfVk3eYe39VdVWtLi4iAAAAAMBy2rOgrapDSc4neSTJiSRnq+rELnNvS/KbSb606JAAAAAAAMtoyBO0J5Osd/eN7n49yXNJzuwy93tJPpbkPxaYDwAAAABgaQ0paI8kuTlz3ti+9m1V9VCSY939uQVmAwAAAABYakMK2trlWn/7ZtX3JPlEkg/v+UVV56pqrarWNjc3h6cEDoy9hGmxkzA99hKmxU7C9NhL2J8hBe1GkmMz56NJbs2c35bkXUm+UFX/muTdSS7u9ofCuvuZ7l7t7tWVlZW7Tw0sjL2EabGTMD32EqbFTsL02EvYnyEF7ZUkx6vqgaq6J8ljSS5+62Z3v9bd93X3/d19f5IXkpzu7rUDSQwAAAAAsCT2LGi7+40kTyS5nOTlJBe6+2pVPV1Vpw86IAAAAADAsjo8ZKi7LyW5tOPaU7eZfXj/sQAAAAAAlt+QVxwAAAAAAHAAFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwEgUtAAAAAMBIFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwEgUtAAAAAMBIFLQAAAAAACNR0AIAAAAAjERBCwAAAAAwEgUtAAAAAMBIBhW0VXWqqq5X1XpVPbnL/Q9V1bWqeqmqPl9VP7b4qAAAAAAAy2XPgraqDiU5n+SRJCeSnK2qEzvGvpxktbt/Kslnk3xs0UEBAAAAAJbNkCdoTyZZ7+4b3f16kueSnJkd6O7nu/sb28eNCK5TAAAVuklEQVQXkhxdbEwAAAAAgOUzpKA9kuTmzHlj+9rtPJ7k73a7UVXnqmqtqtY2NzeHpwQOjL2EabGTMD32EqbFTsL02EvYnyEFbe1yrXcdrPrlJKtJPr7b/e5+prtXu3t1ZWVleErgwNhLmBY7CdNjL2Fa7CRMj72E/Tk8YGYjybGZ89Ekt3YOVdX7kvx2kv/W3d9cTDwAAAAAgOU15AnaK0mOV9UDVXVPkseSXJwdqKqHknwyyenufmXxMQEAAAAAls+eBW13v5HkiSSXk7yc5EJ3X62qp6vq9PbYx5P8QJK/rqp/qqqLt/k6AAAAAAC2DXnFQbr7UpJLO649NfP5fQvOBQAAAACw9Ia84gAAAAAAgAOgoAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRDCpoq+pUVV2vqvWqenKX+99XVX+1ff9LVXX/ooMCAAAAACybPQvaqjqU5HySR5KcSHK2qk7sGHs8yavd/eNJPpHkDxYdFAAAAABg2Qx5gvZkkvXuvtHdryd5LsmZHTNnkvz59ufPJnlvVdXiYgIAAAAALJ/DA2aOJLk5c95I8rO3m+nuN6rqtSQ/lOSrs0NVdS7Jue3jN6vqK3cT+oDdlx25J2Sq2eSaz0+MHWCWvdwXueY31WyT2Us7uW9TzSbX/OzlfKb6u5xqrmS62aaay07Ob6q/S7nmM9Vcib2c11R/l1PNlUw321Rz3fVOVnffeaDqF5P8Qnf/j+3zf09ysrs/ODNzdXtmY/v8f7dnvnaH713r7tW7DX5QppormW42ueYz1VzJdLPJNZ+p5kqmm02u+Uw1VzLdbHLNb6rZ5JrPVHMl080m13ymmiuZbja55jPVXMl0s8k1n6nmSqabbRlzDXnFwUaSYzPno0lu3W6mqg4neXuSr99NIAAAAACAt4ohBe2VJMer6oGquifJY0ku7pi5mORXtz+/P8nf916P5gIAAAAAvMXt+Q7a7XfKPpHkcpJDST7V3Ver6ukka919McmfJflMVa1n68nZxwb87Gf2kfsgTTVXMt1scs1nqrmS6WaTaz5TzZVMN5tc85lqrmS62eSa31SzyTWfqeZKpptNrvlMNVcy3WxyzWequZLpZpNrPlPNlUw329Ll2vMdtAAAAAAAHIwhrzgAAAAAAOAAKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJHsWtFX1qap6paq+cpv7VVV/WFXrVfVSVf304mMCAAAAACyfIU/QfjrJqTvcfyTJ8e1/55L88f5jAQAAAAAsvz0L2u7+hyRfv8PImSR/0VteSPKOqvqRRQUEAAAAAFhWhxfwHUeS3Jw5b2xf+/edg1V1LltP2ebee+/9mQcffHABPx6+u7z44otf7e6VsXN8i72Eae2lnYQt9hKmxU7C9NhLmJb97GR1995DVfcn+Vx3v2uXe/8rye939//ZPn8+yf/s7hfv9J2rq6u9trZ2N5nhu1pVvdjdq2Pn2I295K1qqntpJ3krs5cwLXYSpsdewrTsZyeHvIN2LxtJjs2cjya5tYDvBQAAAABYaosoaC8m+ZXa8u4kr3X3m15vAAAAAADAd9rzHbRV9WySh5PcV1UbSX43yfcmSXf/SZJLSR5Nsp7kG0l+/aDCAgAAAAAskz0L2u4+u8f9TvIbC0sEAAAAAPAWsYhXHAAAAAAAcBcUtAAAAAAAI1HQAgAAAACMREELAAAAADASBS0AAAAAwEgUtAAAAAAAI1HQAgAAAACMREELAAAAADASBS0AAAAAwEgUtAAAAAAAI1HQAgAAAACMREELAAAAADCSQQVtVZ2qqutVtV5VT+5y/0er6vmq+nJVvVRVjy4+KgAAAADActmzoK2qQ0nOJ3kkyYkkZ6vqxI6x30lyobsfSvJYkj9adFAAAAAAgGUz5Anak0nWu/tGd7+e5LkkZ3bMdJIf3P789iS3FhcRAAAAAGA5HR4wcyTJzZnzRpKf3THz0ST/u6o+mOTeJO9bSDoAAAAAgCU25Ana2uVa7zifTfLp7j6a5NEkn6mqN313VZ2rqrWqWtvc3Jw/LbBw9hKmxU7C9NhLmBY7CdNjL2F/hhS0G0mOzZyP5s2vMHg8yYUk6e4vJvn+JPft/KLufqa7V7t7dWVl5e4SAwtlL2Fa7CRMj72EabGTMD32EvZnSEF7Jcnxqnqgqu7J1h8Bu7hj5t+SvDdJquons1XQ+l8mAAAAAAB3sGdB291vJHkiyeUkLye50N1Xq+rpqjq9PfbhJB+oqn9O8mySX+vuna9BAAAAAABgxpA/EpbuvpTk0o5rT818vpbkPYuNBgAAAACw3Ia84gAAAAAAgAOgoAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEaioAUAAAAAGImCFgAAAABgJApaAAAAAICRKGgBAAAAAEYyqKCtqlNVdb2q1qvqydvM/FJVXauqq1X1l4uNCQAAAACwfA7vNVBVh5KcT/LzSTaSXKmqi919bWbmeJKPJHlPd79aVT98UIEBAAAAAJbFkCdoTyZZ7+4b3f16kueSnNkx84Ek57v71STp7lcWGxMAAAAAYPkMKWiPJLk5c97YvjbrnUneWVX/WFUvVNWp3b6oqs5V1VpVrW1ubt5dYmCh7CVMi52E6bGXMC12EqbHXsL+DCloa5drveN8OMnxJA8nOZvkT6vqHW/6j7qf6e7V7l5dWVmZNytwAOwlTIudhOmxlzAtdhKmx17C/gwpaDeSHJs5H01ya5eZv+3u/+zuf0lyPVuFLQAAwP/f3v2FWlaeZwB/3jiYUmr/oFMoaqOhk9KpFAyDJDdpQqQdLczc2DKCkIBUktb2wlKwCCLmotSQCgWhFRpqA60aL9ohjAw0VVJCxjigNf7BMp0KDrZ1mqTeBDVDv16crdlne2ZmrTN77/Xl+PvBwN5rf571sPZ+/OA9m3UAADiLIQPap5Psqaqrq+riJIeSHF5Y8w9JPpUkVXVZNm55cHKZQQEAAAAAdprzDmhba2eS3J7kaJKXkjzaWnuhqu6tqgOzZUeTfLeqXkzyRJI/bq19d1WhAQAAAAB2gl1DFrXWjiQ5snDs7rnHLckds38AAAAAAAww5BYHAAAAAACsgAEtAAAAAMBEDGgBAAAAACZiQAsAAAAAMBEDWgAAAACAiRjQAgAAAABMxIAWAAAAAGAiBrQAAAAAABMxoAUAAAAAmIgBLQAAAADARAxoAQAAAAAmYkALAAAAADCRQQPaqtpfVS9X1YmquvMc626qqlZV+5YXEQAAAABgZzrvgLaqLkryQJIbkuxNcnNV7d1i3SVJ/jDJU8sOCQAAAACwEw35Bu11SU601k621t5O8nCSg1us+0KS+5K8ucR8AAAAAAA71pAB7eVJXp17fmp27F1VdW2SK1trXzvXD6qq26rqeFUdP3369OiwwPLpJfRFJ6E/egl90Unoj17ChRkyoK0tjrV3X6z6QJL7k/zR+X5Qa+3B1tq+1tq+3bt3D08JrIxeQl90Evqjl9AXnYT+6CVcmCED2lNJrpx7fkWS1+aeX5LkmiRPVtUrST6W5LA/FAYAAAAAcG5DBrRPJ9lTVVdX1cVJDiU5/M6LrbU3WmuXtdauaq1dleRYkgOtteMrSQwAAAAAsEOcd0DbWjuT5PYkR5O8lOTR1toLVXVvVR1YdUAAAAAAgJ1q15BFrbUjSY4sHLv7LGs/eeGxAAAAAAB2viG3OAAAAAAAYAUMaAEAAAAAJmJACwAAAAAwEQNaAAAAAICJGNACAAAAAEzEgBYAAAAAYCIGtAAAAAAAEzGgBQAAAACYiAEtAAAAAMBEDGgBAAAAACZiQAsAAAAAMBEDWgAAAACAiQwa0FbV/qp6uapOVNWdW7x+R1W9WFXPVdXXq+pDy48KAAAAALCznHdAW1UXJXkgyQ1J9ia5uar2Lix7Jsm+1tqvJXksyX3LDgoAAAAAsNMM+QbtdUlOtNZOttbeTvJwkoPzC1prT7TWfjB7eizJFcuNCQAAAACw8wwZ0F6e5NW556dmx87m1iSPX0goAAAAAID3gyED2triWNtyYdUtSfYl+eJZXr+tqo5X1fHTp08PTwmsjF5CX3QS+qOX0BedhP7oJVyYIQPaU0munHt+RZLXFhdV1fVJ7kpyoLX21lY/qLX2YGttX2tt3+7du7eTF1gyvYS+6CT0Ry+hLzoJ/dFLuDBDBrRPJ9lTVVdX1cVJDiU5PL+gqq5N8lfZGM6+vvyYAAAAAAA7z3kHtK21M0luT3I0yUtJHm2tvVBV91bVgdmyLyb5qSRfrapnq+rwWX4cAAAAAAAzu4Ysaq0dSXJk4djdc4+vX3IuAAAAAIAdb8gtDgAAAAAAWAEDWgAAAACAiRjQAgAAAABMxIAWAAAAAGAiBrQAAAAAABMxoAUAAAAAmIgBLQAAAADARAxoAQAAAAAmYkALAAAAADARA1oAAAAAgIkY0AIAAAAATMSAFgAAAABgIoMGtFW1v6perqoTVXXnFq9/sKoemb3+VFVdteygAAAAAAA7zXkHtFV1UZIHktyQZG+Sm6tq78KyW5N8v7X2S0nuT/Jnyw4KAAAAALDTDPkG7XVJTrTWTrbW3k7ycJKDC2sOJnlo9vixJJ+uqlpeTAAAAACAnWfIgPbyJK/OPT81O7blmtbamSRvJLl0GQEBAAAAAHaqXQPWbPVN2LaNNamq25LcNnv6VlU9P+D863ZZkv+ZOsRZ9JpNrnF+eeoA8/Tygsg1Xq/ZuumlTl6wXrPJNZ5ejtPre9lrrqTfbL3m0snxen0v5Rqn11yJXo7V63vZa66k32y95tp2J6u198xRNy+o+niSe1prvzl7/idJ0lr707k1R2drvlVVu5L8V5Ld7Rw/vKqOt9b2bTf4qvSaK+k3m1zj9Jor6TebXOP0mivpN5tc4/SaK+k3m1zj9ZpNrnF6zZX0m02ucXrNlfSbTa5xes2V9JtNrnF6zZX0m20n5hpyi4Onk+ypqqur6uIkh5IcXlhzOMlnZo9vSvLP5xrOAgAAAAAw4BYHrbUzVXV7kqNJLkry5dbaC1V1b5LjrbXDSf46yVeq6kSS72VjiAsAAAAAwDkMuQdtWmtHkhxZOHb33OM3k/z2yHM/OHL9uvSaK+k3m1zj9Jor6TebXOP0mivpN5tc4/SaK+k3m1zj9ZpNrnF6zZX0m02ucXrNlfSbTa5xes2V9JtNrnF6zZX0m23H5TrvPWgBAAAAAFiNIfegBQAAAABgBVY+oK2q/VX1clWdqKo7t3j9g1X1yOz1p6rqqlVnGpjrjqp6saqeq6qvV9WHesg1t+6mqmpVtba/WjckW1X9zuy6vVBVf9dDrqr6xap6oqqemb2fN64p15er6vWqev4sr1dV/cUs93NV9dE15eqykwOz6eXIXDq56bxddnJ27i572Wsnh2SbW6eXA3Lp5Zbn1ssl5ppbp5MDs03RS51cSS575TZy2Ss3nVcvl5/LXjkyl71y0zlX08nW2sr+ZeOPiv17kg8nuTjJvybZu7Dm95L85ezxoSSPrDLTiFyfSvKTs8ef7yXXbN0lSb6R5FiSfavONeKa7UnyTJKfmz3/+U5yPZjk87PHe5O8sqZr9okkH03y/FlevzHJ40kqyceSPNXJ9Vp7J0dk08tx10snN5+3u06OuGb2ypHZZuv0cnguvRx/zfRyRK7ZOp0cl23tvdTJleSyV46/ZvbKzefVy+XnsleOu172ys3nXEknV/0N2uuSnGitnWytvZ3k4SQHF9YcTPLQ7PFjST5dVTV1rtbaE621H8yeHktyxYozDco184Uk9yV5cw2ZxmT73SQPtNa+nySttdc7ydWS/PTs8c8keW0NudJa+0aS751jycEkf9s2HEvys1X1CyuO1WsnB2XTy9G5dHL+pH12Mum3l712clC2Gb0cnksvN9PLJeea0clx2dbeS51cfi575bZy2SvnT6qXS89lrxydy145f8IVdXLVA9rLk7w69/zU7NiWa1prZ5K8keTSDnLNuzUb0+9VO2+uqro2yZWtta+tIc+8IdfsI0k+UlXfrKpjVbW/k1z3JLmlqk4lOZLkD9aQa4ixn8N1nXOKTg7NNu/93kudXL4pOjn0vPbKzfRy+bnuiV6OPa9e/ohOribbPemvlzo5Ptc8e2W/vfxx7WSil9vJNc9e2Wcnh2a7J/31clud3LWyOBu2+s1I28aaZRt8zqq6Jcm+JL++0kSz021x7N1cVfWBJPcn+ewasiwacs12ZeOr75/Mxm+g/qWqrmmt/e/EuW5O8jettS9V1ceTfGWW6/9WmGuIXj/7U+QadV693Dj1Fsd08sL0/Nnv9f8XGwvX28lEL1eRSy/Hn1cv5063xTGdvPBsPfZSJ7d5Tnvlu3rt5Y9rJxO9XNRrL3VyNdl67OW2Pver/gbtqSRXzj2/Iu/9uvG7a6pqVza+knyurwqvK1eq6vokdyU50Fp7a8WZhuS6JMk1SZ6sqleycS+Lw2u6cfTQ9/IfW2s/bK39R5KXs1HiqXPdmuTRJGmtfSvJTyS5bMW5hhj0OZzgnFN0cmg2vRye6501OjncFJ0cel575bhsejk+l16OP69eDs+lk9vL1mMvdXJ8LnvluFzvrLFXDqeX43PZK4fnemeNvXK47XWyrfbGubuSnExydX50Q99fXVjz+9l80+hHV5lpRK5rs3Ez4j2rzjMm18L6J7O+PxI25JrtT/LQ7PFl2fhK96Ud5Ho8yWdnj39lVoxa03W7Kme/cfRvZfONo7/dyfu49k6OyKaX466XTr43X1edHHHN7JUjsy2s10u9XMU108sRuRbWv687OSLbJL3UyaXnsleOv2b2yvfm08vl5rJXjrte9sr3Zlt6J9fxIbwxyb/NPvx3zY7dm43fUiQb0+2vJjmR5NtJPrzqTANz/VOS/07y7Ozf4R5yLaxdS2FHXLNK8udJXkzynSSHOsm1N8k3Z2V+NslvrCnX3yf5zyQ/zMZvUG5N8rkkn5u7Xg/Mcn9nXe9lr50cmE0vx10vndycq8tODrxm9sqR2RbW6qVeruKa6eWIXAtr3/edHJht7b3UyZXksleOv2b2ys259HL5ueyV466XvXJzppV0smb/MQAAAAAAa7bqe9ACAAAAAHAWBrQAAAAAABMxoAUAAAAAmIgBLQAAAADARAxoAQAAAAAmYkALAAAAADARA1oAAAAAgIkY0AIAAAAATOT/Acm2d/Em+hayAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1728x648 with 24 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = sns.color_palette('icefire', n_colors=15)\n",
    "fig, axes = plt.subplots(4,6, sharex=True, sharey=True, figsize=(24,9))\n",
    "axes = axes.flatten()\n",
    "model.eval()\n",
    "vmf = vMF(LATENT_DIM, kappa=500)\n",
    "\n",
    "k = 0\n",
    "for ix in random_indices:                   \n",
    "    rw_rep = rw_i[ix]\n",
    "\n",
    "    # get the encoded random walks. This only works if I have passed the data through already\n",
    "    mus = model.h[ix*n_walks: ix*n_walks+n_walks]\n",
    "    orig_seq_len = seq_len[ix*n_walks: ix*n_walks+n_walks].cpu()\n",
    "    decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=orig_seq_len ,\n",
    "                             n_samples=2, max_trg_len=walk_length, min_angle=np.pi/2.4, init_state=trg[0,ix*n_walks])\n",
    "    \n",
    "    # cluster the rws\n",
    "    clustered_rws = []\n",
    "    clustered_results = []\n",
    "    for rws in decoded_rws:\n",
    "        clus_res, clus_rws = get_clustered_rws_agglom(rws, dist_thresh=.25)\n",
    "        clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "        clustered_results.append(clus_res)\n",
    "    clustered_rws = np.vstack(clustered_rws)\n",
    "    # reduce to trees\n",
    "    new_neurons = []\n",
    "    for clus_res in clustered_results:\n",
    "        N = tree_from_clustered_result(clus_res)\n",
    "        new_neurons.append(N)\n",
    "    \n",
    "    if k == 0 or k ==3:\n",
    "        c= colors[0]\n",
    "    elif k == 6 or k ==9:\n",
    "        c= colors[2]\n",
    "    elif k == 12 or k ==15:\n",
    "        c= colors[4]  \n",
    "    elif k == 18 or k ==21:\n",
    "        c= colors[6]\n",
    "    \n",
    "    neurons[indices[ix]].draw_2D(ax=axes[k], dendrite_color=c, projection='xy')\n",
    "    axes[k].axis('off')\n",
    "    axes[k].set_aspect('equal')\n",
    "    \n",
    "    for l in range(k+1,k+3):\n",
    "        \n",
    "        sampled_rws = decoded_rws[l-k-1]\n",
    "        axes[l].plot(sampled_rws[:,:,0].T, sampled_rws[:,:,1].T, c='darkgrey')\n",
    "        axes[l].axis('off')\n",
    "        axes[l].set_aspect('equal')\n",
    "        new_neurons[l-k-1].draw_2D(projection='xy', dendrite_color='k', ax=axes[l])\n",
    "    k += 3\n",
    "fig.subplots_adjust(hspace=-.1, wspace=-.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neurons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f89dc410c8a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'neurons' is not defined"
     ]
    }
   ],
   "source": [
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_neurons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b92e4475c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_neurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_neurons' is not defined"
     ]
    }
   ],
   "source": [
    "new_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
