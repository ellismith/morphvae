{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "from utils.vmf_batch import vMF\n",
    "from models import SeqEncoder, SeqDecoder, Seq2Seq_VAE, PoolingClassifier\n",
    "from utils.cluster_utils import _convert_cluster_results_dict_into_array, get_clustered_rws_agglom, tree_from_clustered_result\n",
    "from utils.sampling_utils import _fill_with_infty, decode_z, sample_rws\n",
    "\n",
    "## plotting ###\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/toy_data/3_populations/walk_representation_32.npy', 'rb') as f:\n",
    "    walk_representation = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/toy_data/3_populations/iterator/test_iterator.pkl', 'rb') as f:\n",
    "    test_iterator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "# get data\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "src_data, trg_data, seq_len, indices, labels = list(test_iterator)[0]\n",
    "rw_i = np.round(trg_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 45.709938049316406\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "INPUT_DIM = 3\n",
    "EMBED_DIM = 32\n",
    "HIDDEN_DIM = 32\n",
    "LATENT_DIM = 32\n",
    "NUM_LAYERS = 2\n",
    "KAPPA = 500\n",
    "DROPOUT =.1\n",
    "\n",
    "# model\n",
    "enc = SeqEncoder(INPUT_DIM, EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT)\n",
    "dec = SeqDecoder(INPUT_DIM, EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT)\n",
    "dist = vMF(LATENT_DIM, kappa=KAPPA, device=device)\n",
    "model = Seq2Seq_VAE(enc, dec, dist, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('./models/3_populations/emb32_hid32_lat32_dp0.1_k500_max_frac1.0_run1_best.pt')\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    bs, n_walks, walk_length, input_dim = src_data.shape\n",
    "    src = src_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    # src = [walk length , bs * n_walks, input_dim]\n",
    "    trg = trg_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    seq_len = seq_len.view(-1).to(device)\n",
    "    output = model(src, seq_len, trg, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(indices)):\n",
    "    \n",
    "    for kappa in [100,300,500]:\n",
    "        \n",
    "        vmf = vMF(LATENT_DIM, kappa=kappa)\n",
    "        mus = model.h[k*n_walks: k*n_walks+n_walks]\n",
    "        original_seq_len = seq_len[k*n_walks: k*n_walks+n_walks].cpu()\n",
    "        decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,\n",
    "                                 n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "\n",
    "         # cluster the rws\n",
    "        clustered_rws = []\n",
    "        clustered_results = []\n",
    "        for rws in decoded_rws:\n",
    "            clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.5 )\n",
    "            clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "            clustered_results.append(clus_res)\n",
    "        clustered_rws = np.vstack(clustered_rws)\n",
    "        # reduce to trees\n",
    "        for clus_res in clustered_results:\n",
    "            N = tree_from_clustered_result(clus_res)\n",
    "            N.write_to_swc('%i'%indices[k], path='./data/toy_data/3_populations/sampled_neurons/test_data/v3/k%i/'%kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On real data\n",
    "\n",
    "## M1 EXC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/M1_exc_data/walks/walk_representation.npy', 'rb') as f:\n",
    "    walk_representation = np.load(f)\n",
    "\n",
    "with open('./data/M1_exc_data/iterator/m_labels/test_iterator.pkl', 'rb') as f:\n",
    "    test_iterator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "# get data\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "src_data, trg_data, seq_len, indices, labels = list(test_iterator)[0]\n",
    "rw_i = np.round(trg_data, 2)\n",
    "\n",
    "N, n_walks, walk_length, input_dim = src_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model with the best validation loss \n",
    "state_dict = torch.load('./models/M1_exc/m_label/finetuned_vae_k500_frac1.0_best_run2.pt', map_location=device)\n",
    "model.load_state_dict(state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    bs, n_walks, walk_length, input_dim = src_data.shape\n",
    "    src = src_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    # src = [walk length , bs * n_walks, input_dim]\n",
    "    trg = trg_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    seq_len = seq_len.view(-1).to(device)\n",
    "    %timeit -r 3 -n 10 output = model(src, seq_len, trg, 0)\n",
    "    output = model(src, seq_len, trg, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 45.709938049316406\n",
      "128 ms ± 482 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
      "26.2 ms ± 7.51 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "3.4 ms ± 1.3 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "### time the code: ####\n",
    "timing = []\n",
    "k = 0\n",
    "kappa = 500\n",
    "\n",
    "vmf = vMF(LATENT_DIM, kappa=kappa, device=device)\n",
    "mus = model.h[k*n_walks: k*n_walks+n_walks]\n",
    "original_seq_len = seq_len[k*n_walks: k*n_walks+n_walks].cpu()\n",
    "\n",
    "o = %timeit -r 3 -n 100 -o decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "timing.append(('sampling', o))\n",
    "\n",
    "decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,\n",
    "                         n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "\n",
    "# cluster the rws\n",
    "clustered_rws = []\n",
    "clustered_results = []\n",
    "for rws in decoded_rws:\n",
    "    o = %timeit -r 3 -o clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.4 )\n",
    "    timing.append(('clustering', o))\n",
    "    clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.4 )\n",
    "    \n",
    "    clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "    clustered_results.append(clus_res)\n",
    "clustered_rws = np.vstack(clustered_rws)\n",
    "# reduce to trees\n",
    "for clus_res in clustered_results:\n",
    "    o = %timeit -r 3 -o N = tree_from_clustered_result(clus_res)\n",
    "    timing.append(('get_tree', o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for k in range(len(indices)):\n",
    "    \n",
    "    for kappa in [100,300,500]:\n",
    "        \n",
    "        vmf = vMF(LATENT_DIM, kappa=kappa, device=device)\n",
    "        mus = model.h[k*n_walks: k*n_walks+n_walks]\n",
    "        original_seq_len = seq_len[k*n_walks: k*n_walks+n_walks].cpu()\n",
    "        decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,\n",
    "                                 n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "\n",
    "         # cluster the rws\n",
    "        clustered_rws = []\n",
    "        clustered_results = []\n",
    "        for rws in decoded_rws:\n",
    "            clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.4 )\n",
    "            clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "            clustered_results.append(clus_res)\n",
    "        clustered_rws = np.vstack(clustered_rws)\n",
    "        # reduce to trees\n",
    "        for clus_res in clustered_results:\n",
    "            N = tree_from_clustered_result(clus_res)\n",
    "            N.write_to_swc('%i'%indices[k], path='./data/M1_exc_data/sampled_neurons/test_data/k%i/'%kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1 Inh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/M1_inh_data/walks/axon/walk_representation_32.npy', 'rb') as f:\n",
    "    walk_representation = np.load(f)\n",
    "\n",
    "with open('./data/M1_inh_data/iterator/axon/test_iterator_32.pkl', 'rb') as f:\n",
    "    test_iterator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "# get data\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "src_data, trg_data, seq_len, indices, labels = list(test_iterator)[0]\n",
    "rw_i = np.round(trg_data, 2)\n",
    "\n",
    "N, n_walks, walk_length, input_dim = src_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model with the best validation loss \n",
    "state_dict = torch.load('./models/M1_inh/finetuned/axon/finetuned_vae_frac0.5_best_run2.pt',map_location=device)\n",
    "model.load_state_dict(state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.47 s ± 9.08 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    bs, n_walks, walk_length, input_dim = src_data.shape\n",
    "    src = src_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    # src = [walk length , bs * n_walks, input_dim]\n",
    "    trg = trg_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    seq_len = seq_len.view(-1).to(device)\n",
    "    %timeit -r 3 -n 10 output = model(src, seq_len, trg, 0)\n",
    "    output = model(src, seq_len, trg, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 45.709938049316406\n",
      "119 ms ± 760 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
      "51.4 ms ± 48.4 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "6.44 ms ± 2.6 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "### time the code: ####\n",
    "k = 0\n",
    "kappa = 500\n",
    "\n",
    "vmf = vMF(LATENT_DIM, kappa=kappa, device=device)\n",
    "mus = model.h[k*n_walks: k*n_walks+n_walks]\n",
    "original_seq_len = seq_len[k*n_walks: k*n_walks+n_walks].cpu()\n",
    "\n",
    "o = %timeit -r 3 -n 100 -o decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "timing.append(('inh', 'sampling', o))\n",
    "\n",
    "decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,\n",
    "                         n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "\n",
    "# cluster the rws\n",
    "clustered_rws = []\n",
    "clustered_results = []\n",
    "for rws in decoded_rws:\n",
    "    o = %timeit -r 3 -o clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.4 )\n",
    "    timing.append(('inh','clustering', o))\n",
    "    clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.4 )\n",
    "    \n",
    "    clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "    clustered_results.append(clus_res)\n",
    "clustered_rws = np.vstack(clustered_rws)\n",
    "# reduce to trees\n",
    "for clus_res in clustered_results:\n",
    "    o = %timeit -r 3 -o N = tree_from_clustered_result(clus_res)\n",
    "    timing.append(('inh', 'get_tree', o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(indices)):\n",
    "    \n",
    "    for kappa in [100,300,500]:\n",
    "        \n",
    "        vmf = vMF(LATENT_DIM, kappa=kappa)\n",
    "        mus = model.h[k*n_walks: k*n_walks+n_walks]\n",
    "        original_seq_len = seq_len[k*n_walks: k*n_walks+n_walks].cpu()\n",
    "        decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,\n",
    "                                 n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "\n",
    "         # cluster the rws\n",
    "        clustered_rws = []\n",
    "        clustered_results = []\n",
    "        for rws in decoded_rws:\n",
    "            clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.3)\n",
    "            clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "            clustered_results.append(clus_res)\n",
    "        clustered_rws = np.vstack(clustered_rws)\n",
    "        # reduce to trees\n",
    "        for clus_res in clustered_results:\n",
    "            N = tree_from_clustered_result(clus_res)\n",
    "            N.write_to_swc('%i'%indices[k], path='./data/M1_inh_data/sampled_neurons/axon/test_data/k%i/'%kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Farrow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = 'soma_centered'\n",
    "\n",
    "with open('./data/Farrow_data/walks/%s/walk_representation.npy'%part, 'rb') as f:\n",
    "    walk_representation = np.load(f)\n",
    "\n",
    "with open('./data/Farrow_data/iterator/%s/test_iterator.pkl'%part, 'rb') as f:\n",
    "    test_iterator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 17\n",
    "\n",
    "# get data\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "src_data, trg_data, seq_len, indices, labels = list(test_iterator)[0]\n",
    "rw_i = np.round(trg_data, 2)\n",
    "\n",
    "N, n_walks, walk_length, input_dim = src_data.shape\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = dict(input_dim =3, embed_dim=32, hidden_dim=32, latent_dim=32, num_layers = 2, kappa=500, dropout=.1)\n",
    "\n",
    "LATENT_DIM = config['latent_dim']\n",
    "\n",
    "# model with the best validation mse loss \n",
    "state_dict = torch.load('./models/Farrow/finetuned/%s/finetuned_vae_frac0.0_best_run1.pt'%part, map_location=device)\n",
    "model.load_state_dict(state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.96 s ± 3.08 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    bs, n_walks, walk_length, input_dim = src_data.shape\n",
    "    src = src_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    # src = [walk length , bs * n_walks, input_dim]\n",
    "    trg = trg_data.view(-1,walk_length,input_dim).transpose(0,1).to(device)\n",
    "    seq_len = seq_len.view(-1).to(device)\n",
    "    %timeit -r 3 -n 10 output = model(src, seq_len, trg, 0)\n",
    "    output = model(src, seq_len, trg, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 45.709938049316406\n",
      "129 ms ± 418 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n",
      "42.3 ms ± 15 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "5.62 ms ± 4.64 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# time the code\n",
    "\n",
    "### time the code: ####\n",
    "k = 0\n",
    "kappa = 500\n",
    "timing = []\n",
    "vmf = vMF(LATENT_DIM, kappa=kappa, device=device)\n",
    "mus = model.h[k*n_walks: k*n_walks+n_walks]\n",
    "original_seq_len = seq_len[k*n_walks: k*n_walks+n_walks].cpu()\n",
    "\n",
    "o = %timeit -r 3 -n 100 -o decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "timing.append(('rgc', 'sampling', o))\n",
    "\n",
    "decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,\n",
    "                         n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "\n",
    "# cluster the rws\n",
    "clustered_rws = []\n",
    "clustered_results = []\n",
    "for rws in decoded_rws:\n",
    "    o = %timeit -r 3 -o clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.4 )\n",
    "    timing.append(('rgc','clustering', o))\n",
    "    clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.4 )\n",
    "    \n",
    "    clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "    clustered_results.append(clus_res)\n",
    "clustered_rws = np.vstack(clustered_rws)\n",
    "# reduce to trees\n",
    "for clus_res in clustered_results:\n",
    "    o = %timeit -r 3 -o N = tree_from_clustered_result(clus_res)\n",
    "    timing.append(('rgc', 'get_tree', o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n",
      "KLD: 21.207782745361328\n",
      "KLD: 37.62336730957031\n",
      "KLD: 45.709938049316406\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(indices)):\n",
    "    \n",
    "    for kappa in [100,300,500]:\n",
    "        \n",
    "        vmf = vMF(LATENT_DIM, kappa=kappa)\n",
    "        mus = model.h[k*n_walks: k*n_walks+n_walks]\n",
    "        original_seq_len = seq_len[k*n_walks: k*n_walks+n_walks].cpu()\n",
    "        decoded_rws = sample_rws(model, vmf, mus, orig_seq_len=original_seq_len,\n",
    "                                 n_samples=1, max_trg_len=walk_length, min_angle=np.pi/2.4)\n",
    "\n",
    "         # cluster the rws\n",
    "        clustered_rws = []\n",
    "        clustered_results = []\n",
    "        for rws in decoded_rws:\n",
    "            clus_res, clus_rws = get_clustered_rws_agglom(rws,dist_thresh=.25)\n",
    "            clustered_rws.append(clus_rws.reshape((1,)+clus_rws.shape))\n",
    "            clustered_results.append(clus_res)\n",
    "        clustered_rws = np.vstack(clustered_rws)\n",
    "        # reduce to trees\n",
    "        for clus_res in clustered_results:\n",
    "            N = tree_from_clustered_result(clus_res)\n",
    "            N.write_to_swc('%i'%indices[k], path='./data/Farrow_data/sampled_neurons/soma_centered/test_data/k%i/'%kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urban data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/urban_data/walks/soma_centered/walk_representation.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ellismith/morphvae/Sample neurons.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bspike/home/ellismith/morphvae/Sample%20neurons.ipynb#ch0000032vscode-remote?line=0'>1</a>\u001b[0m part \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msoma_centered\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bspike/home/ellismith/morphvae/Sample%20neurons.ipynb#ch0000032vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m./data/urban_data/walks/\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m/walk_representation.npy\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%\u001b[39;49mpart, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bspike/home/ellismith/morphvae/Sample%20neurons.ipynb#ch0000032vscode-remote?line=3'>4</a>\u001b[0m     walk_representation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bspike/home/ellismith/morphvae/Sample%20neurons.ipynb#ch0000032vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./data/urban_data/iterator/\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/test_iterator.pkl\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39mpart, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/urban_data/walks/soma_centered/walk_representation.npy'"
     ]
    }
   ],
   "source": [
    "part = 'soma_centered'\n",
    "\n",
    "with open('./data/urban_data/walks/%s/walk_representation.npy'%part, 'rb') as f:\n",
    "    walk_representation = np.load(f)\n",
    "\n",
    "with open('./data/urban_data/iterator/%s/test_iterator.pkl'%part, 'rb') as f:\n",
    "    test_iterator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "\n",
    "# get data\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "src_data, trg_data, seq_len, indices, labels = list(test_iterator)[0]\n",
    "rw_i = np.round(trg_data, 2)\n",
    "\n",
    "N, n_walks, walk_length, input_dim = src_data.shape\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = dict(input_dim =3, embed_dim=32, hidden_dim=32, latent_dim=32, num_layers = 2, kappa=500, dropout=.1)\n",
    "\n",
    "LATENT_DIM = config['latent_dim']\n",
    "\n",
    "# model with the best validation mse loss \n",
    "state_dict = torch.load('./models/Farrow/finetuned/%s/finetuned_vae_frac0.0_best_run1.pt'%part, map_location=device)\n",
    "model.load_state_dict(state_dict['model_state_dict'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
