{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from utils.vmf_batch import vMF\n",
    "\n",
    "from models import SeqEncoder, SeqDecoder, Seq2Seq_VAE, PoolingClassifier, init_weights\n",
    "from utils.training_utils import train, evaluate\n",
    "\n",
    "## plotting ###\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/urban_data/iterator/soma_centered/train_iterator.pkl', 'rb') as f:\n",
    "    train_iterator = pickle.load(f)\n",
    "\n",
    "with open('./data/urban_data/iterator/soma_centered/val_iterator.pkl', 'rb') as f:\n",
    "    val_iterator = pickle.load(f)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data, trg_data, seq_len, indices, labels = list(train_iterator)[0]\n",
    "bs, n_walks, walk_length, output_dim = src_data.shape\n",
    "\n",
    "N_train = len(train_iterator.sampler.indices)\n",
    "N_val = len(val_iterator.sampler.indices)\n",
    "\n",
    " \n",
    "MASKING_ELEMENT = train_iterator.dataset.masking_el\n",
    "\n",
    "# get number of labels, ignore -100 index\n",
    "l = list(np.unique(labels))\n",
    "if -100 in l:\n",
    "    l.remove(-100)\n",
    "NUM_CLASSES = len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_iterator.dataset.labels[train_iterator.sampler.indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 18.465579986572266\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 16\n",
    "latent_dim = 8\n",
    "NUM_LAYERS = 2\n",
    "dpout = .1\n",
    "kap = 500\n",
    "pool = 'max'\n",
    "lr = 0.01\n",
    "\n",
    "enc = SeqEncoder(output_dim, emb_dim, emb_dim, NUM_LAYERS, dpout)\n",
    "dec = SeqDecoder(output_dim, emb_dim, emb_dim, NUM_LAYERS, dpout)\n",
    "dist = vMF(latent_dim, kappa=kap)\n",
    "model = Seq2Seq_VAE(enc, dec, dist, device).to(device)\n",
    "classifier = PoolingClassifier(latent_dim, NUM_CLASSES, n_walks,dpout,pooling=pool).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x, reconstructed_x, ignore_el=MASKING_ELEMENT):\n",
    "    # reconstruction loss\n",
    "    # x = [trg len, batch size * n walks, output dim]\n",
    "\n",
    "    seq_len , bs, output_dim = x.shape\n",
    "    mask = x[:,:,0] != ignore_el\n",
    "    RCL = 0\n",
    "    for d in range(output_dim):\n",
    "        RCL += mse_loss(reconstructed_x[:,:,d][mask], x[:,:,d][mask])\n",
    "    RCL /= output_dim\n",
    "    \n",
    "    return RCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./models/urban\"\n",
    "import os \n",
    "os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 0, Train Loss: 40629.15, Val Loss: 78029.20, Time elapsed [s]: 8.13\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 1, Train Loss: 32131.54, Val Loss: 59257.32, Time elapsed [s]: 8.09\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 2, Train Loss: 25241.97, Val Loss: 50901.64, Time elapsed [s]: 8.02\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 3, Train Loss: 22086.95, Val Loss: 46637.57, Time elapsed [s]: 8.08\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 4, Train Loss: 20192.21, Val Loss: 46124.75, Time elapsed [s]: 8.16\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 5, Train Loss: 19218.65, Val Loss: 41309.50, Time elapsed [s]: 8.21\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 6, Train Loss: 17818.83, Val Loss: 39508.28, Time elapsed [s]: 8.12\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 7, Train Loss: 16903.80, Val Loss: 38100.17, Time elapsed [s]: 8.17\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 8, Train Loss: 16062.37, Val Loss: 36575.05, Time elapsed [s]: 8.02\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 9, Train Loss: 15388.38, Val Loss: 35570.55, Time elapsed [s]: 8.15\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 10, Train Loss: 14594.93, Val Loss: 33605.96, Time elapsed [s]: 8.01\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 11, Train Loss: 13915.00, Val Loss: 31960.09, Time elapsed [s]: 8.12\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 12, Train Loss: 13243.66, Val Loss: 30679.02, Time elapsed [s]: 8.01\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% |  6% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 13% |\n",
      "Epoch 13, Train Loss: 12652.81, Val Loss: 29047.16, Time elapsed [s]: 8.12\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  6% |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fb4c97789905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             train_loss, train_class_loss = train(model, classifier, train_iterator, optimizer, \n\u001b[1;32m     40\u001b[0m                                                \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                                                  class_fraction=frac)\n\u001b[0m\u001b[1;32m     42\u001b[0m             val_loss, val_class_loss = evaluate(model,classifier, val_iterator,\n\u001b[1;32m     43\u001b[0m                                                  calculate_loss, cross_entropy_loss, norm_p=None)\n",
      "\u001b[0;32m~/morphvae/utils/training_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, classifier, iterator, optimizer, model_criterion, classifier_criterion, clip, norm_p, class_fraction, ignore_index)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#trg = [trg len, batch size * n walks, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/packages/7x/anaconda3/5.3.0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/morphvae/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_len, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m#last hidden states of the encoder is used as the initial hidden states of the decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m#first input to the decoder is the first coordinate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/morphvae/models.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, src, src_len)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# sample from vMF distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_bow_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/morphvae/utils/vmf_batch.py\u001b[0m in \u001b[0;36mbuild_bow_rep\u001b[0;34m(self, lat_code, n_sample)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/morphvae/utils/vmf_batch.py\u001b[0m in \u001b[0;36msample_cell\u001b[0;34m(self, mu, norm, kappa)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# mu = GVar(mu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_weight_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/morphvae/utils/vmf_batch.py\u001b[0m in \u001b[0;36m_sample_weight_batch\u001b[0;34m(self, kappa, dim, batch_sz)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/morphvae/utils/vmf_batch.py\u001b[0m in \u001b[0;36m_sample_weight\u001b[0;34m(self, kappa, dim)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# concentrates towards 0.5 as d-> inf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             if kappa * w + dim * np.log(1. - x * w) - c >= np.log(\n\u001b[1;32m    127\u001b[0m                     u):  # thresh is dim *(kdiv * (w-x) + log(1-x*w) -log(1-x**2))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "N_EPOCHS= 200\n",
    "save_path_model= './models/urban/finetuned/soma_centered/finetuned_vae_frac%.1f_best_run%i.pt'\n",
    "save_path_losses = './models/urban/finetuned/soma_centered/finetuned_losses_frac%.1f_run%i.npy'\n",
    "save_path_elapsed_time = './models/urban/finetuned/soma_centered/finetuned_elapsed_time_frac%.1f_run%i.npy'\n",
    "state_dict = torch.load('./models/parameter_search/emb16_hid16_lat8_dp0.1_k500_avg_run1_best.pt')\n",
    "# start with the 5 pop toy data, \"true\" finetuning on the urban data\n",
    "# loads in parameters from 5 pop toy data, updates from what it learns from urban\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "for frac in [1., .9, .5, .1, 0.]:\n",
    "    \n",
    "  \n",
    "    runs = range(1,4)\n",
    "        \n",
    "    for run in runs:\n",
    "        \n",
    "        # load pre-trained model\n",
    "        # the first run was the best\n",
    "        model.load_state_dict(state_dict['model_state_dict'])\n",
    "        classifier.apply(init_weights)\n",
    "        cross_entropy_loss = torch.nn.CrossEntropyLoss(reduction='sum', ignore_index=-100)\n",
    "        mse_loss = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "        #optimizer\n",
    "        optimizer = optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=lr)\n",
    "       \n",
    "        best_test_loss = np.infty\n",
    "\n",
    "        losses = np.load('./models/parameter_search/losses_emb16_hid16_lat8_dp0.1_k500_avg_1.npy')\n",
    "        elapsed_time = np.zeros((N_EPOCHS))\n",
    "        training = list(losses[:,:2])\n",
    "        validation = list(losses[:,2:])\n",
    "        \n",
    "        for e in range(N_EPOCHS):\n",
    "            start.record()\n",
    "            train_loss, train_class_loss = train(model, classifier, train_iterator, optimizer, \n",
    "                                               calculate_loss,cross_entropy_loss, clip=1, norm_p=None,\n",
    "                                                 class_fraction=frac)\n",
    "            val_loss, val_class_loss = evaluate(model,classifier, val_iterator,\n",
    "                                                 calculate_loss, cross_entropy_loss, norm_p=None)\n",
    "\n",
    "            train_loss /= N_train\n",
    "            train_class_loss /= N_train\n",
    "            val_loss /= N_val\n",
    "            val_class_loss /=N_val\n",
    "            \n",
    "            end.record()\n",
    "\n",
    "            # Waits for everything to finish running\n",
    "            torch.cuda.synchronize()\n",
    "            elapsed_time[e] = start.elapsed_time(end) # milliseconds\n",
    "            \n",
    "            training += [[train_loss,train_class_loss]]\n",
    "            validation += [[val_loss, val_class_loss]]\n",
    "            print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Val Loss: {val_loss:.2f}, Time elapsed [s]: {elapsed_time[e]/1000:.2f}')\n",
    "\n",
    "\n",
    "            if e % 50 == 0 and e > 0:\n",
    "                optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr']/2\n",
    "\n",
    "            if best_test_loss > val_loss:\n",
    "                best_test_loss = val_loss\n",
    "                torch.save({'epoch': e,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'classifier_state_dict': classifier.state_dict()\n",
    "                               },save_path_model%(frac, run))\n",
    "\n",
    "                validation_ = np.array(validation)\n",
    "                training_ = np.array(training)\n",
    "                # [:,0] = training loss, [:,1] = training classification loss \n",
    "                # [:,2] validation loss, [:,3] validation classification loss\n",
    "                losses = np.hstack((training_, validation_))\n",
    "                np.save(save_path_losses%(frac, run),losses)\n",
    "                np.save(save_path_elapsed_time%(frac,run),elapsed_time)\n",
    "        validation = np.array(validation)\n",
    "        training = np.array(training)\n",
    "        losses = np.hstack((training, validation))\n",
    "        np.save(save_path_losses%(frac, run), losses)\n",
    "        np.save(save_path_elapsed_time%(frac,run),elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(validation)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time.mean()/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "z = torch.load('./models/urban/scratch/soma_centered/vae_frac0.0_scaled_best_run2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
